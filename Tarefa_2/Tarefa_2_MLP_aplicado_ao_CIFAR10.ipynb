{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-f9NvLs5Xbip"
   },
   "source": [
    "# Objetivos deste trabalho\n",
    "- Familiarizar-se com a biblioteca PyTorch\n",
    "- Definir arquiteturas MLP simples em PyTorch\n",
    "- Treinar utilizando CIFAR10, testando diferentes arquiteturas, parâmetros, funções de loss e otimizadores\n",
    "- Comparar os resultados obtidos utilizando apenas Perpceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialização "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-dryJOgqXbis"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iNwiNEXsXbi0",
    "outputId": "2bf2b76f-bfeb-4bdd-9c9c-1d09b3e7dcfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Carregar os datasets\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "dataset_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OVOxPTltXbi8"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dataset_train, batch_size=50, \n",
    "                          shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(dataset=dataset_test, batch_size=50, \n",
    "                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amnqhJ4Igrhr"
   },
   "source": [
    "# Definindo as Arquiteturas MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIweDBXpXbjA"
   },
   "outputs": [],
   "source": [
    "# Arquitetura MLP com três Camadas Ocultas\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    # Construtor da Classe MLP\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32, 512)\n",
    "        self.fc2 = nn.Linear(512,   256)\n",
    "        self.fc3 = nn.Linear(256,   128)\n",
    "        self.fc4 = nn.Linear(128,    10)\n",
    "        self.activation_function = nn.ReLU()\n",
    "    \n",
    "    # Função Forward\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32)\n",
    "        x = self.activation_function(self.fc1(x))\n",
    "        x = self.activation_function(self.fc2(x))\n",
    "        x = self.activation_function(self.fc3(x))\n",
    "        x = self.activation_function(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação se é possivel utilizar _cuda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jWu-v-q7XbjF",
    "outputId": "11d86a5c-400c-4cda-ed7c-bf3a8fcf51fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Confere se pode utilizar cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Imprime o dispotivo\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impressão dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Dtj4cSzfXbjK",
    "outputId": "ca7c567b-de15-4f9a-88e5-9aabb280b5dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGD + L1', 'SGD + MSE', 'SGD + CrossEntropy', 'ADAM + L1', 'ADAM + MSE', 'ADAM + CrossEntropy', 'RMSprop + L1', 'RMSprop + MSE', 'RMSprop + CrossEntropy')\n"
     ]
    }
   ],
   "source": [
    "# Vai ser necessário 9 modelos, pois temos 3 Otimizadores e 3 funções de Loss\n",
    "# e será feito todas as combinações possiveis\n",
    "\n",
    "# Inicializa os 9 modelos\n",
    "models = []\n",
    "for i in range(9):\n",
    "    model = MLP()\n",
    "    models.append(model.to(device))\n",
    "\n",
    "models_types = ('SGD + L1', 'SGD + MSE', 'SGD + CrossEntropy',\n",
    "                'ADAM + L1', 'ADAM + MSE', 'ADAM + CrossEntropy',\n",
    "                'RMSprop + L1', 'RMSprop + MSE', 'RMSprop + CrossEntropy')    \n",
    "\n",
    "# Imprime os modelos\n",
    "#print(models)\n",
    "print(models_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo os Otimizadores e as Funções de Loss para cada Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPgWmBhbXbjP"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Otimizadores para o Modelo de 1 camada oculta\n",
    "\n",
    "# Inicialização\n",
    "i = 0\n",
    "optimizers = []\n",
    "\n",
    "# Os três primeiros utilizam SGD\n",
    "for _ in range(3):\n",
    "    optimizers.append(torch.optim.SGD(models[i].parameters(), lr=0.001, momentum=0.9))\n",
    "    i += 1\n",
    "\n",
    "# Os três seguintes utilizam ADAM\n",
    "for _ in range(3):\n",
    "    optimizers.append(torch.optim.Adam(models[i].parameters(), lr=0.001))\n",
    "    i += 1\n",
    "\n",
    "# Os três ultimos utilizam RMSprop\n",
    "for _ in range(3):\n",
    "    optimizers.append(torch.optim.RMSprop(models[i].parameters(), lr=0.001, momentum=0.9))\n",
    "    i += 1\n",
    "    \n",
    "#print(models_types)\n",
    "#print(optimizers)\n",
    "\n",
    "# Funções de Loss\n",
    "loss_L1 = nn.L1Loss()\n",
    "loss_MSE = nn.MSELoss()\n",
    "loss_CE = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a função de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4284
    },
    "colab_type": "code",
    "id": "y5Gi1bc0XbjT",
    "outputId": "584170ba-8dee-4d6e-bc14-6f3c773599ed"
   },
   "outputs": [],
   "source": [
    "# Função de Treinamento \n",
    "def train(dataset, model, optimizer, loss_fn, epochs=20):\n",
    "    \n",
    "    # Vetor de Loss Inicializado\n",
    "    loss_array = []\n",
    "    \n",
    "    # Percore pelo número de épocas\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Inicializa o running_loss em 0\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Percorre todo o dataset\n",
    "        for i, data in enumerate(dataset, 0):\n",
    "\n",
    "            # Pega a Entrada e o Label\n",
    "            input, label = data\n",
    "            \n",
    "            # Transforma para o device\n",
    "            input, label = input.to(device), label.to(device)\n",
    "\n",
    "            # Zera os parâmetros dos gradientes\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Passa as entradas pelo modelo\n",
    "            output = model(input)\n",
    "            \n",
    "            # Calcula o loss com a função escolhida\n",
    "            loss = loss_fn(output, label)\n",
    "            \n",
    "            # Propaga o erro\n",
    "            loss.backward()\n",
    "            \n",
    "            # Atualiza os pesos\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Soma ao loss\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Imprime o loss desta época\n",
    "        loss_array.append(running_loss/len(dataset))\n",
    "        print('[%3d] loss: %.4f' %\n",
    "             (epoch + 1, loss_array[-1]))\n",
    "    \n",
    "    # Retorna o array com os Loss em cada época\n",
    "    return loss_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a Função de Avalaliação do Dataset por um modelo especifico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HlQ7NaqPXbja",
    "outputId": "20ab4b8f-7025-490a-f10e-29096a62681a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Função de avaliação do modelo num conjunto passado\n",
    "def evaluate(dataset, model, type_of_images='test'):\n",
    "    \n",
    "    # Inicialização\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    # Percorre todo o dataset\n",
    "    with torch.no_grad():\n",
    "        for data in dataset:\n",
    "            \n",
    "            # Transforma para o device\n",
    "            image, label = data\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            \n",
    "            # Recebe a saida do modelo\n",
    "            output = model(image)\n",
    "            \n",
    "            # Faz o resultado dos labels das saidas\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            \n",
    "            # Confere se o resultado foi igual o label para dar acerto\n",
    "            total += 1 \n",
    "            correct += (predicted == label).sum().item()\n",
    "    \n",
    "    # Imprime a acurácia do dataset para tal modelo\n",
    "    print('Accuracy of the network on the %d %s images: %d %%' % \n",
    "          ( len(test_loader),  type_of_images, 100 * correct / total))\n",
    "    \n",
    "    # Retorna a acurácia\n",
    "    return (100 * correct / total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hs78u5teXbjk"
   },
   "source": [
    "# __TREINAMENTO DOS MODELOS__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGD + L1', 'SGD + MSE', 'SGD + CrossEntropy', 'ADAM + L1', 'ADAM + MSE', 'ADAM + CrossEntropy', 'RMSprop + L1', 'RMSprop + L1', 'RMSprop + CrossEntropy')\n"
     ]
    }
   ],
   "source": [
    "print(models_types)\n",
    "loss_array = []\n",
    "acuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando SGD + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array.append(train(train_loader, models[0], optimizers[0], loss_L1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando SGD + MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array.append(train(train_loader, models[1], optimizers[1], loss_MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando SGD + CrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array.append(train(train_loader, models[2], optimizers[2], loss_CE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando ADAM + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array.append(train(train_loader, models[3], optimizers[3], loss_L1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando ADAM + MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array.append(train(train_loader, models[4], optimizers[4], loss_MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando ADAM + CrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array.append(train(train_loader, models[5], optimizers[5], loss_CE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizado RMSprop + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array.append(train(train_loader, models[6], optimizers[6], loss_L1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizado RMSprop + MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array.append(train(train_loader, models[7], optimizers[7], loss_MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizado RMSprop + CrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array.append(train(train_loader, models[8], optimizers[8], loss_CE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos da Loss em Cada Época para todos os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passa por Todos os modelos\n",
    "for i in range(9):\n",
    "    # Imprime o Gráfico de Desempenho de Loss\n",
    "    plt.title(models_types[i])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(loss_array[i], 'b-')\n",
    "    plt.show()\n",
    "    \n",
    "    # Imprime a acurácia do Dataset de Teste\n",
    "    acuracies.append(evaluate(test_loader, models[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos de Barras diferenciando a acurácia entre cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.arange(9)\n",
    "plt.bar(x, acuracies)\n",
    "plt.xticks(x, models_types)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Tarefa_2_MLP_aplicado_ao_CIFAR10.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
